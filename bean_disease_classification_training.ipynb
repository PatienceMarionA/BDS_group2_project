{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bean Disease Classification Model Training\n",
        "\n",
        "This notebook trains a deep learning model to classify bean diseases from images.\n",
        "\n",
        "## Dataset Structure\n",
        "- **Classes**: als (Angular Leaf Spot), bean_rust, healthy, unknown\n",
        "- **Splits**: training, validation, test\n",
        "\n",
        "## Model Strategy\n",
        "- Using **MobileNetV2** (lightweight, CPU-friendly)\n",
        "- Transfer learning from ImageNet weights\n",
        "- Small batch size (16-32) for CPU training\n",
        "- Data augmentation for better generalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.20.0\n",
            "GPU Available: []\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Dataset Paths and Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "BASE_DIR = Path('Classification')\n",
        "TRAIN_DIR = BASE_DIR / 'training'\n",
        "VAL_DIR = BASE_DIR / 'validation'\n",
        "TEST_DIR = BASE_DIR / 'test'\n",
        "\n",
        "# Model parameters (CPU-optimized)\n",
        "IMG_SIZE = 224  # Standard size for MobileNetV2\n",
        "BATCH_SIZE = 16  # Small batch size for CPU (adjust if you have more RAM)\n",
        "EPOCHS = 30  # Start with 30, can increase if needed\n",
        "LEARNING_RATE = 0.0001  # Lower learning rate for fine-tuning\n",
        "\n",
        "# Get class names from directory structure\n",
        "CLASS_NAMES = sorted([d.name for d in TRAIN_DIR.iterdir() if d.is_dir()])\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "print(f\"Classes: {CLASS_NAMES}\")\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "\n",
        "# Count images in each split\n",
        "def count_images(directory):\n",
        "    \"\"\"Count total images in a directory (including subdirectories)\"\"\"\n",
        "    count = 0\n",
        "    for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "        count += len(list(directory.rglob(ext)))\n",
        "    return count\n",
        "\n",
        "train_count = count_images(TRAIN_DIR)\n",
        "val_count = count_images(VAL_DIR)\n",
        "test_count = count_images(TEST_DIR)\n",
        "\n",
        "print(f\"\\nTraining images: {train_count}\")\n",
        "print(f\"Validation images: {val_count}\")\n",
        "print(f\"Test images: {test_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Data Generators with Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation for training (helps model generalize better)\n",
        "# Using moderate augmentation to avoid overfitting and keep training time reasonable\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Random rotation up to 20 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2,  # Random vertical shift\n",
        "    shear_range=0.2,  # Random shear transformation\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flip\n",
        "    fill_mode='nearest'  # Fill pixels outside boundaries\n",
        ")\n",
        "\n",
        "# No augmentation for validation and test (only normalization)\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "print(\"Creating data generators...\")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"\\nClass indices: {train_generator.class_indices}\")\n",
        "print(f\"Training batches per epoch: {len(train_generator)}\")\n",
        "print(f\"Validation batches: {len(val_generator)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample images from each class\n",
        "def visualize_samples(generator, num_samples=4):\n",
        "    \"\"\"Display sample images from the generator\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    # Get a batch of images\n",
        "    x_batch, y_batch = next(generator)\n",
        "    \n",
        "    for i in range(min(num_samples, len(x_batch))):\n",
        "        axes[i].imshow(x_batch[i])\n",
        "        class_idx = np.argmax(y_batch[i])\n",
        "        class_name = list(generator.class_indices.keys())[class_idx]\n",
        "        axes[i].set_title(f'Class: {class_name}', fontsize=12)\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Sample training images:\")\n",
        "visualize_samples(train_generator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build the Model (Transfer Learning with MobileNetV2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained MobileNetV2 model (trained on ImageNet)\n",
        "# We'll use it as a feature extractor and add our classification head\n",
        "print(\"Loading MobileNetV2 base model...\")\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,  # Don't include the classification head\n",
        "    weights='imagenet',  # Use pre-trained ImageNet weights\n",
        "    alpha=1.0  # Width multiplier (1.0 = full width, smaller = faster but less accurate)\n",
        ")\n",
        "\n",
        "# Freeze the base model initially (we'll unfreeze later for fine-tuning)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the complete model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),  # Convert feature maps to vectors\n",
        "    layers.Dropout(0.5),  # Regularization to prevent overfitting\n",
        "    layers.Dense(128, activation='relu'),  # Dense layer for feature learning\n",
        "    layers.Dropout(0.3),  # Additional regularization\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')  # Output layer (4 classes)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', 'top_k_categorical_accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Calculate model size\n",
        "total_params = model.count_params()\n",
        "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Callbacks for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory for saving models\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Callbacks for training\n",
        "callbacks = [\n",
        "    # Save the best model based on validation accuracy\n",
        "    ModelCheckpoint(\n",
        "        'models/bean_disease_best_model.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    \n",
        "    # Stop training if validation accuracy doesn't improve for 5 epochs\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    \n",
        "    # Reduce learning rate if validation loss plateaus\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,  # Reduce LR by half\n",
        "        patience=3,  # Wait 3 epochs\n",
        "        min_lr=1e-7,  # Minimum learning rate\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Callbacks configured:\")\n",
        "print(\"- ModelCheckpoint: Saves best model based on validation accuracy\")\n",
        "print(\"- EarlyStopping: Stops training if no improvement for 5 epochs\")\n",
        "print(\"- ReduceLROnPlateau: Reduces learning rate when validation loss plateaus\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train the Model (Phase 1: Feature Extraction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting Phase 1: Feature Extraction Training\")\n",
        "print(\"Training with frozen base model (faster, good starting point)\")\n",
        "print(f\"This may take a while on CPU. Please be patient...\\n\")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nPhase 1 training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Fine-tuning (Phase 2: Unfreeze Base Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unfreeze the base model for fine-tuning\n",
        "# We'll only fine-tune the last few layers to avoid overfitting\n",
        "print(\"Unfreezing base model for fine-tuning...\")\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze early layers, fine-tune later layers\n",
        "# This is a common practice: early layers learn general features, later layers learn specific features\n",
        "for layer in base_model.layers[:-20]:  # Freeze all but last 20 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * 0.1),  # 10x smaller LR\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', 'top_k_categorical_accuracy']\n",
        ")\n",
        "\n",
        "# Count trainable parameters\n",
        "trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "print(f\"Trainable parameters after unfreezing: {trainable_params:,}\")\n",
        "print(\"\\nStarting Phase 2: Fine-tuning\")\n",
        "print(\"This will take longer but should improve accuracy...\\n\")\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,  # Fewer epochs for fine-tuning\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nFine-tuning completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Visualize Training History\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine histories from both phases\n",
        "def combine_histories(hist1, hist2):\n",
        "    \"\"\"Combine two training histories\"\"\"\n",
        "    combined = {}\n",
        "    for key in hist1.history.keys():\n",
        "        combined[key] = hist1.history[key] + hist2.history[key]\n",
        "    return combined\n",
        "\n",
        "if 'history_finetune' in globals():\n",
        "    combined_history = combine_histories(history, history_finetune)\n",
        "else:\n",
        "    combined_history = history.history\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(combined_history['accuracy'], label='Training Accuracy', marker='o')\n",
        "axes[0].plot(combined_history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(combined_history['loss'], label='Training Loss', marker='o')\n",
        "axes[1].plot(combined_history['val_loss'], label='Validation Loss', marker='s')\n",
        "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal Training Accuracy: {combined_history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {combined_history['val_accuracy'][-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "print(\"Loading best model for evaluation...\")\n",
        "best_model = keras.models.load_model('models/bean_disease_best_model.h5')\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_results = best_model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
        "\n",
        "print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
        "if len(test_results) > 2:\n",
        "    print(f\"Test Top-K Accuracy: {test_results[2]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Generate Classification Report and Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predictions on test set\n",
        "print(\"Generating predictions on test set...\")\n",
        "test_generator.reset()\n",
        "predictions = best_model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Classification report\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Save Final Model and Class Mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Save the final model\n",
        "final_model_path = 'models/bean_disease_final_model.h5'\n",
        "best_model.save(final_model_path)\n",
        "print(f\"Final model saved to: {final_model_path}\")\n",
        "\n",
        "# Save class indices for later use (important for Streamlit app)\n",
        "class_mapping = {\n",
        "    'class_indices': test_generator.class_indices,\n",
        "    'class_names': class_names,\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'img_size': IMG_SIZE\n",
        "}\n",
        "\n",
        "with open('models/class_mapping.json', 'w') as f:\n",
        "    json.dump(class_mapping, f, indent=2)\n",
        "\n",
        "print(f\"Class mapping saved to: models/class_mapping.json\")\n",
        "print(f\"\\nClass mapping:\")\n",
        "for class_name, idx in test_generator.class_indices.items():\n",
        "    print(f\"  {class_name}: {idx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Test Prediction on Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(model, image_path, class_names, img_size=224):\n",
        "    \"\"\"\n",
        "    Predict the class of a single image\n",
        "    \n",
        "    Args:\n",
        "        model: Trained Keras model\n",
        "        image_path: Path to the image file\n",
        "        class_names: List of class names\n",
        "        img_size: Target image size\n",
        "    \n",
        "    Returns:\n",
        "        predicted_class: Name of predicted class\n",
        "        confidence: Confidence score\n",
        "        all_probs: Probabilities for all classes\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert('RGB')  # Ensure RGB format\n",
        "    img = img.resize((img_size, img_size))\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    \n",
        "    # Predict\n",
        "    predictions = model.predict(img_array, verbose=0)\n",
        "    predicted_idx = np.argmax(predictions[0])\n",
        "    predicted_class = class_names[predicted_idx]\n",
        "    confidence = predictions[0][predicted_idx]\n",
        "    \n",
        "    # Get all probabilities\n",
        "    all_probs = {class_names[i]: float(predictions[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    return predicted_class, confidence, all_probs\n",
        "\n",
        "# Test on a few sample images from test set\n",
        "print(\"Testing predictions on sample images:\\n\")\n",
        "\n",
        "# Get a few random test images\n",
        "test_image_paths = []\n",
        "for class_name in class_names:\n",
        "    class_dir = TEST_DIR / class_name\n",
        "    if class_dir.exists():\n",
        "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
        "        if images:\n",
        "            test_image_paths.append(images[0])  # Take first image from each class\n",
        "\n",
        "# Display predictions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, img_path in enumerate(test_image_paths[:4]):\n",
        "    predicted_class, confidence, all_probs = predict_image(best_model, img_path, class_names, IMG_SIZE)\n",
        "    \n",
        "    # Display image\n",
        "    img = Image.open(img_path)\n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].set_title(f'Predicted: {predicted_class}\\nConfidence: {confidence:.2%}', \n",
        "                       fontsize=11, fontweight='bold')\n",
        "    axes[idx].axis('off')\n",
        "    \n",
        "    print(f\"Image: {img_path.name}\")\n",
        "    print(f\"  Predicted: {predicted_class} ({confidence:.2%})\")\n",
        "    print(f\"  All probabilities: {all_probs}\")\n",
        "    print()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/sample_predictions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Model Training Complete! âœ…\n",
        "\n",
        "**Files Created:**\n",
        "- `models/bean_disease_best_model.h5` - Best model based on validation accuracy\n",
        "- `models/bean_disease_final_model.h5` - Final trained model\n",
        "- `models/class_mapping.json` - Class indices and metadata (needed for Streamlit app)\n",
        "- `models/training_history.png` - Training curves\n",
        "- `models/confusion_matrix.png` - Confusion matrix visualization\n",
        "- `models/sample_predictions.png` - Sample predictions\n",
        "\n",
        "**Next Steps:**\n",
        "1. Review the training history and confusion matrix\n",
        "2. If accuracy is satisfactory, proceed to build the Streamlit interface\n",
        "3. The model and class mapping are ready to be used in the Streamlit app\n",
        "\n",
        "**Note:** Training on CPU can be slow. If you need faster training:\n",
        "- Reduce batch size further (e.g., 8)\n",
        "- Reduce image size (e.g., 192)\n",
        "- Skip fine-tuning phase\n",
        "- Use fewer epochs\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
